---
title: "EDS 231: Assignment 2"
author: "Juliet Cohen, Charles Hendrickson,Scout Leonard, Peter Menzies"
date: '`r format(Sys.time(), "%m/%d/%Y")`'
output: pdf_document
header-includes:
  - \setlength{\parindent}{1em}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load libraries
library(jsonlite)  
library(tidyverse) 
library(tidytext) 
library(here)
library(LexisNexisTools)
library(tidytext)
library(sentimentr)
library(janitor)
```

# Download Data

## Three Mile Island Accident data

```{r three mile data}
threemileisland_files <- list.files(pattern = ".docx",
                                    path = here("data/threemileisland"),
                                    full.names = TRUE,
                                    recursive = TRUE,
                                    ignore.case = TRUE)

threemileisland_data <- lnt_read(threemileisland_files) #Object of class 'LNT output'

threemileisland_meta_df <- threemileisland_data@meta %>% 
  rename(Art_ID = ID)

threemileisland_articles_df <- threemileisland_data@articles

threemileisland_paragraphs_df <- threemileisland_data@paragraphs

#joined df with paraagraphs and dates 
threemileisland_df <- full_join(threemileisland_paragraphs_df,
                                threemileisland_meta_df)
```

## Chernobyl disaster data

```{r chernobyl data}
chernobyl_files <- list.files(pattern = ".docx",
                              path = here("data/chernobyl"),
                              full.names = TRUE,
                              recursive = TRUE,
                              ignore.case = TRUE)

chernobyl_data <- lnt_read(chernobyl_files) #Object of class 'LNT output'

chernobyl_meta_df <- chernobyl_data@meta
chernobyl_articles_df <- chernobyl_data@articles
chernobyl_paragraphs_df <- chernobyl_data@paragraphs

chernobyl_df<- data_frame(element_id = seq(1:length(chernobyl_meta_df$Headline)),
                                Date = chernobyl_meta_df$Date,
                                Headline = chernobyl_meta_df$Headline)
```

## Fukashima disaster data

```{r fukashima data}
library(sentimentr)
# NOTE: FOR DISCUSSION, DESCRIBE HOW WE TOOK MEAN SENITMENT OF PARAGRAPHS RATHER THAN ARTICLE (PERHAPS MORE ACCURATE)

fukashima_files <- list.files(pattern = ".docx",
                         path = here("data/fukashima"),
                         full.names = TRUE,
                         recursive = TRUE,
                         ignore.case = TRUE)

fukashima_data <- lnt_read(fukashima_files) #Object of class 'LNT output'

fukashima_meta_df <- fukashima_data@meta %>% 
  rename(Art_ID = ID)

fukashima_articles_df <- fukashima_data@articles

fukashima_paragraphs_df <- fukashima_data@paragraphs

#joined df with paragraphs and dates 
fukashima_df <- full_join(fukashima_paragraphs_df,
                                fukashima_meta_df)
```

## Sentiment time series

Read in sentiment analysis Lexicon:

```{r}
bing_sent <- get_sentiments('bing')
```

### Three Mile Island disaster

#### Process data 

First, we create a dataframe that contains every sentence from publications before and after the disaster and their sentiments:

```{r}
#get sentences from three mile island paragraphs
threemileisland_text <- get_sentences(threemileisland_df$Paragraph)

#get sentiment from each sentence
threemileisland_sent <- sentiment(threemileisland_text)

#join sentiment dataframe with article info (this way, our dataframe contains dates)
threemileisland_sent_df <- inner_join(threemileisland_df, 
                                   threemileisland_sent,
                                   by = c("Par_ID" = "element_id")) %>% 
  select(c("Par_ID", "sentiment", "Paragraph", "Date", "Newspaper"))
```

Next, we find the mean sentiment of each paragraph in all our publication data for this event:

```{r}
#find mean sentiment per paragraph
threemileisland_sent_paragraphs <- threemileisland_sent_df %>% 
  group_by(Par_ID) %>% 
  summarise(paragraph_sent  = mean(sentiment)) 

# catgorize for ggplot
threemileisland_sent <- threemileisland_sent_paragraphs %>%
  mutate(sent_category = case_when(
    paragraph_sent < 0 ~ "negative",
    paragraph_sent == 0 ~ "neutral",
    paragraph_sent > 0 ~ "positive"
  )) %>% 
  inner_join(threemileisland_df, by = "Par_ID")

#generate counts of sentiment sentences by date to plot
threemileisland_sent_plot <- threemileisland_sent %>%
  count(sent_category, Date)
```

#### Visualize sentiment

```{r}
#plot it UP
threemileisland_date <- which(threemileisland_df$Date %in% as.Date("1978-03-28"))

ggplot(data = threemileisland_sent_plot, aes(x = Date, y = n)) +
         geom_line(aes(color = sent_category)) +
  theme_minimal() +
  labs(y = "Developed Media Sentiment (no. headlines)",
       x = "Date",
       title = "Three Mile Island Publication Text Sentiment Analysis") +
  scale_color_manual(values = c("blue", "grey", "red")) +
  theme(plot.title = element_text(size = 20, hjust = 0.5),
        axis.title = element_text(size = 15),
        axis.text = element_text(size = 10)) +
  geom_vline(xintercept = as.numeric(threemileisland_df$Date[threemileisland_date]),
             col = "black")
```

### Chernobyl disaster

### Fukashima disaster

#### Process data 

```{r}
fukashima_text <- get_sentences(fukashima_df$Paragraph)
fukashima_sent <- sentiment(fukashima_text) # neutral = 0.0000, scale -1 to 1, 0.06 = slightly positive, etc.

# this tool considers more than just individual words, it understands the diff btw "it is too late" and "it is not too late"
# 
fukashima_sent_df <- inner_join(fukashima_df, fukashima_sent, by = c("Par_ID" = "element_id"))
```

#### Visualize sentiment time series 

```{r}
# select only relevant columns
fukashima_sent_df_subset <- fukashima_sent_df %>% 
  select(Par_ID, Paragraph, Newspaper, Date, sentiment)

# approximate the sentiment (polarity of text) by grouping by paragraph
fukashima_sent_summary <- fukashima_sent_df_subset %>%
  group_by(Par_ID) %>%
  summarize(sentiment_average = mean(sentiment))

fukashima_sent_summary_date <- left_join(fukashima_sent_summary, fukashima_sent_df_subset, by = "Par_ID") %>% 
  select(Par_ID, sentiment_average, Date)

#head(fukashima_sent_summary)

#fukashima_sent_summary_df <- as.data.frame(fukashima_sent_summary) 

#colnames(fukashima_sent_summary_df)

#fukashima_sent_summary_df$sentiment_average$ave_sentiment

fukashime_sent_summary_df <- fukashima_sent_summary_df %>% rename(sentiment_average = "sentiment_average$ave_sentiment")




# take a look at the new dataframe arranged from highest ave_sentiment to lowest
fukashima_sent_summary %>%
   arrange(ave_sentiment)

# add pos, neg, neutral words according to the value of sentiment 
fukushima_pos_neg_neutral <- fukashima_sent_summary %>% 
  mutate(sent_category = case_when(
      ave_sentiment < 0 ~ "Negative",
      ave_sentiment > 0 ~ "Positive",
      T ~ "Neutral")) %>% 
  count(sent_category, Date)
```

## Emotion time series

### Three Mile Island disaster

```{r}
#get nrc emotions lexicon
nrc_sent <- get_sentiments('nrc') %>% 
  filter(sentiment != "negative" & sentiment != "positive") 
```

```{r}

```

### Chernobyl disaster

### Fukashima disaster
